{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요청 rows 개수 : 80\n",
      "요청 결과를 확인하고 싶은 경우 `print_result`를 True로 설정해주세요.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def test(i: int, j: int, print_result: bool = True):\n",
    "    \"\"\"\n",
    "    모델 예측에 대한 테스트용 함수 입니다.\n",
    "    i,j는 test에 사용할 row 범위를 나타냅니다.\n",
    "    print_result는 응답 결과에 대한 출력 여부를 설정합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    X_test = pd.read_csv(\"data/X_test.csv\").drop(columns=[\"Name\", \"group\"])\n",
    "    y_test = pd.read_csv(\"data/y_test.csv\")\n",
    "\n",
    "    # request Prediction\n",
    "    payloads = X_test.iloc[i:j].to_dict('list')\n",
    "    req = requests.post(\"http://localhost:8000/predict\", json=payloads)\n",
    "\n",
    "    # to_json\n",
    "    req_json = req.json()\n",
    "    if print_result:\n",
    "        from pprint import pprint\n",
    "\n",
    "        pprint(req_json)\n",
    "\n",
    "    # response Customer_Adaptivity_Level\n",
    "    if req.status_code == 200:\n",
    "        customer_id: list = req_json[\"data\"][\"table_id\"]\n",
    "        customer_Transported: list = y_test[i:j].T.values.tolist()[0]\n",
    "\n",
    "        payloads_result = []\n",
    "        for id, level in zip(customer_id, customer_Transported):\n",
    "            result = dict(id=id, Transported=level)\n",
    "            payloads_result.append(result)\n",
    "        time.sleep(0.1) # predict의 background task 수행을 기다리기 위함.\n",
    "        req = requests.post(\"http://localhost:8000/result\", json=payloads_result)\n",
    "    else:\n",
    "        raise ConnectionError(f'current status code is \"{req.status_code}\" ')\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from random import sample\n",
    "\n",
    "    # 242 = len(y_test)\n",
    "    a, b = sorted(sample(range(242), 2))\n",
    "    # a = 1\n",
    "    # b = 5\n",
    "\n",
    "    print(f\"요청 rows 개수 : {b-a}\")\n",
    "    print(\"요청 결과를 확인하고 싶은 경우 `print_result`를 True로 설정해주세요.\")\n",
    "    test(a, b, print_result=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plot': <Figure size 576x576 with 2 Axes>,\n",
       " 'precision': 82.37082066869301,\n",
       " 'recall': 81.01644245142003,\n",
       " 'accuracy_score': 81.61875945537065}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import datapane as dp\n",
    "\n",
    "def create_metrics(y_true, y_pred, average=\"binary\"):\n",
    "\n",
    "    # create confusion_matrix plots\n",
    "    num = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[True, False])\n",
    "    per = confusion_matrix(y_true=y_true, y_pred=y_pred, normalize=\"pred\", labels=[True, False])\n",
    "\n",
    "    num_con_mat = ConfusionMatrixDisplay(confusion_matrix=num, display_labels=[True, False])\n",
    "    per_con_mat = ConfusionMatrixDisplay(confusion_matrix=per, display_labels=[True, False])\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 8))\n",
    "\n",
    "    num_con_mat.plot(cmap=plt.cm.binary, ax=axes[0], colorbar=False)\n",
    "    per_con_mat.plot(cmap=plt.cm.Blues, ax=axes[1], colorbar=False)\n",
    "\n",
    "    axes[0].set_title(\"Counts\")\n",
    "    axes[1].set_title(\"Rate\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('hi.png',bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    return {\n",
    "        \"plot\": fig,\n",
    "        \"precision\": precision_score(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            average=average,\n",
    "        )\n",
    "        * 100,\n",
    "        \"recall\": recall_score(y_true, y_pred, average=average) * 100,\n",
    "        \"accuracy_score\": accuracy_score(y_true, y_pred) * 100,\n",
    "    }\n",
    "\n",
    "import joblib \n",
    "X_test = pd.read_csv(\"data/X_test.csv\").drop(columns=[\"Name\", \"group\"])\n",
    "rf = joblib.load('models/random_forest.pkl')\n",
    "y_pred = rf.predict(X_test)\n",
    "y_test = pd.read_csv(\"data/y_test.csv\")\n",
    "\n",
    "create_metrics(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2097164ba635ebffc0e3795dc845ae25b57eedf0c1eb5773ded6aee9fc1b279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
